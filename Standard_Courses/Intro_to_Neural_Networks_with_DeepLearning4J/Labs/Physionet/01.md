# Physionet Multivariate TimeSeries Classification Lab
 
In this lab you will build a Neural Network to predict patient mortality based on 2 days worth of data from a stay at the Intensive Care Unit. 
 

## Goals of this lab

This Lab introduces the following 
* Using DataVec to ingest Multivariate Sequence Data
* Building an LSTM for classification of MultiVariate Sequence Data


# Step 1

* Open up IntelliJ
Open up IntelliJ and navigate to the Labs folder

# Step 2 : Review the Data

The Data is stored in the **Top Level** resources folder "src/main/resources". It is easy to confuse this with the "training-labs/src/main/resources" folder. 

## The Labels

The goal is to predict mortality, wether the patient lived or died. The folder "mortality" has one file for patient. Each file has a single line with either a 0 or 1 depending on life or death of the patient


This label will be what we train our neural network to learn to predict. The neural network will predict a label and the predicted label will be compared with the actual label. 

## The Features

Patient data was recorded at differing intervals for each metric,some data was recorded once upon arrival, other data  was recorded once a day, other data more frequently. The original dataset was stored with timestamp, field, value. For our purposes the data has been reorganized in two ways. 

### Resampled Data

The directory "resampled" will have the data resampled to one hour intervals with values averaged over the one hour period. Each file will have 49 lines, one header line and one line with values for each of the 48 time steps. This dataset only has two days worth of data per patient. 

### Data Masking

An additional Field was added to each field, in order to deal with timesteps with a field that was not measured at that timestep a previous value or an imputed value, when a non-measured value is repeated or substituded the flag is set to 1, when a measured value is present the flag is set to 0.  

### Sequence Data

The Directory "sequence" contains the sequence data. 
The first column 'Time'is in hours since patient is admitted to ICU. The second column 'Elapsed' is the time in hours since the last timestep. Each timestep in
the time series is of different length of time. For example, the time between the first and second timestep could be 1 hour, while the time between the second and third timestep could be 2 hours.

Note that the solution provides a flag for choosing wether or not to include the first two time related columns. 

Set remove = 0 to use the original dataset minus the Time and Elapsed columns (84 features)
Set remove = 1 to use the original dataset minus the Time column (85 features)
Set remove = 2 to use the original datset minus the Elapsed column (85 features)
Set remove to another integer to use the original dataset (86 features, including Time and Elapsed columns)


# Step 3

* Review the Java Code



# STEP 4

Set the number of epochs to 25. An epoch is a full pass through the test data. How many epochs are enough? You want the network to train to a point that it generalizes well and has not "overfit" the training data. Using the webui is helpful and comparing with a validation set is also helpful, when scores against the validation test quit improving any further training would lead to overfitting. 

25 epochs was chosen as a reasonable length of time for this class lab. When training a model for production use over a large dataset it make take hours or days to train. In that case it would be a good idea to save a model using modelserializer every so often so you can save your work and start from a pre-trained model.

```
public static final int NB_EPOCHS = 25;
```


# STEP 5: Set additional parameters

Set the following: 

*Random Seed* 

for reproducable results. 

*learning Rate*. 

Learning Rate settings will depend on the network and the data, reasonable values would be in a range from 0.1 to 0.000001. Through trial and error we found 0.032 to be a reasonable value for this network. 

*Batch Size* 

The batch size is the number of training samples your training will use in order to make one update to the model parameters.Too large a batch size may use too much memory. Smaller batch size converges less smoothly. In this case it is set to 40. 

*LSTM Layer Size*

Our network will have a single LSTM layer, set it to a size of 200. 
Generally if the network is too large it has a greater risk of overfitting and takes more resources to calculate each parameter update.If the network is too small it wont have enough parameters to learn the features of the training set. 

 ```
 public static final int RANDOM_SEED = 1234;
 public static final double LEARNING_RATE = 0.032;
 public static final int BATCH_SIZE = 40;
 public static final int lstmLayerSize = 200;
```



# Step 6: Create DataSet Iterators for Train Validation and Test Datasets


A Record Reader returns an iterator over a List of Writables. Writables are an efficient serialization method inspired by Hadoop Writables. 

A Neural Net requires input as an Array of Numeric values. DataSetIterator creates a DataSet tht contains an INDArray of Features and an INDArray of Labels.

```
DataSetIterator trainData;
DataSetIterator validData;
DataSetIterator testData;
		
```		


# Step 7: Create and initialize SequenceRecordReaders for the Train, Validation and Test Data

The measurments are stored in a file in one directory, the labels are stored in files in another directory. The correlation between the two is the number in the filename. To read the data use SequenceRecordReader, to read the Labels use SequenceRecordReader. To build a dataset with both Labels and Features use SequenceRecordReaderDataSetIterator. 



```
// Load the Features
SequenceRecordReader trainFeatures = new CSVSequenceRecordReader(1, ",");
trainFeatures.initialize( new NumberedFileInputSplit(featuresDir.getAbsolutePath() + "/%d.csv", 0, NB_TRAIN_EXAMPLES - 1));

// Load the Labels
    SequenceRecordReader trainLabels = new CSVSequenceRecordReader();
    trainLabels.initialize(new NumberedFileInputSplit(labelsDir.getAbsolutePath() + "/%d.csv", 0, NB_TRAIN_EXAMPLES - 1));
// Combine Labels and Features into DataSet
    trainData = new SequenceRecordReaderDataSetIterator(trainFeatures, trainLabels,
        BATCH_SIZE, numLabelClasses, false, SequenceRecordReaderDataSetIterator.AlignmentMode.ALIGN_END);


// Load validation data
    SequenceRecordReader validFeatures = new CSVSequenceRecordReader(1, ",");
    validFeatures.initialize(new NumberedFileInputSplit(featuresDir.getAbsolutePath() + "/%d.csv", NB_TRAIN_EXAMPLES , NB_TRAIN_EXAMPLES + NB_VALID_EXAMPLES  - 1));
            
// Load the Validation Labels
    SequenceRecordReader validLabels = new CSVSequenceRecordReader();
    validLabels.initialize(new NumberedFileInputSplit(labelsDir.getAbsolutePath() + "/%d.csv", NB_TRAIN_EXAMPLES , NB_TRAIN_EXAMPLES + NB_VALID_EXAMPLES  - 1));

// Combine the Validation Labels and Features into a DataSet
	validData = new SequenceRecordReaderDataSetIterator(validFeatures, validLabels,
        BATCH_SIZE, numLabelClasses, false,SequenceRecordReaderDataSetIterator.AlignmentMode.ALIGN_END);

// Load test data
// Load the Features
    SequenceRecordReader testFeatures = new CSVSequenceRecordReader(1, ",");
        testFeatures.initialize(new NumberedFileInputSplit(featuresDir.getAbsolutePath() + "/%d.csv", NB_TRAIN_EXAMPLES+ NB_VALID_EXAMPLES, NB_TRAIN_EXAMPLES + NB_VALID_EXAMPLES + NB_TEST_EXAMPLES - 1));
            
// Load the Labels
    SequenceRecordReader testLabels = new CSVSequenceRecordReader();
        testLabels.initialize(new NumberedFileInputSplit(labelsDir.getAbsolutePath() + "/%d.csv", NB_TRAIN_EXAMPLES+ NB_VALID_EXAMPLES, NB_TRAIN_EXAMPLES + NB_VALID_EXAMPLES + NB_TEST_EXAMPLES - 1));

// Combine the Labels and Features into a DataSet
    testData = new SequenceRecordReaderDataSetIterator(testFeatures, testLabels,
        BATCH_SIZE, numLabelClasses, false, SequenceRecordReaderDataSetIterator.AlignmentMode.ALIGN_END);


```


# Step 8: Configure  a Neural Network


For this Neural Network we will start with a ComputationGraph Configuration. A Computation Graph allows for more options that a MultiLayerNetwork. 

Add the following code to your class.



```
ComputationGraphConfiguration conf = new NeuralNetConfiguration.Builder()
                .seed(RANDOM_SEED)
                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)
                .learningRate(LEARNING_RATE)
                .weightInit(WeightInit.XAVIER)
                .updater(Updater.ADAM)
                .graphBuilder()
                .addInputs("trainFeatures")
                .setOutputs("predictMortality")
                .addLayer("L1", new GravesLSTM.Builder()
                                .nIn(NB_INPUTS)
                                .nOut(lstmLayerSize)
                                .activation(Activation.TANH)
                                .build(),
                        "trainFeatures")
                .addLayer("predictMortality", new RnnOutputLayer.Builder(LossFunctions.LossFunction.XENT)
                        .activation(Activation.SOFTMAX)
                        .weightInit(WeightInit.XAVIER)
                        .nIn(lstmLayerSize).nOut(numLabelClasses).build(),"L1")
                .pretrain(false).backprop(true)
                .build();
```

# Step 9: Build a Neural Net and add listener

Build a Computation Graph and pass it the configuration built in step 8. 
Initialize the network and set a Listener. A listener reports progress, in this case for each 10 parameter updates our listener will log the score of the network's loss function. 



```
ComputationGraph model = new ComputationGraph(conf);
    model.init();
    model.setListeners(new ScoreIterationListener(10));
```		

# Step 10: Remove the comments to run the code


The last section of code has been commented out, remove the comments, fix any errors you may find and run the code. 

To uncomment find the lines, and remove the "/*" and the "*/"

// STEP #10 REMOVE THE COMMENT BELOW

## Extra Credit


Attach a UI server to the network so you can visualize the training process. 

*Hint* Copy code from SimplestNetwork. 





# <font color="red">END OF Physionet MultiVariate Time Series Lab</font>
