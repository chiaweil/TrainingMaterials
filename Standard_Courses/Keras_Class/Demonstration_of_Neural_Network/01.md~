!SLIDE center subsection

# The Instructor will Demonstrate a Neural Network



!SLIDE

# Simple Neural Network Details
## The Goal: Input=0.5 Output=0.8

![Simple Network](../resources/SimplestNetwork1.png)


!SLIDE

# The Design: 
* Apply Random weights, plus activation function per neuron => output

![Simple Network](../resources/SimplestNetwork2.png)

* Test output: does -0.23 = 0.8 ?

!SLIDE

# Calculate error 
	* backpropagate to adjust weights
	* repeat

![Simple Network](../resources/SimplestNetwork2withbackprop.png)


!SLIDE


# How is Input Handled?

Input to a Neural Network is always Numeric. Typically a MultiDimensional Array, in this case.. not so many dimensions. 

```
INDArray input = Nd4j.create(new float[]{(float) 0.5},new int[]{1,1});
```

Create a 1*1 INDArray with the value 0.5


!SLIDE


# How is Uutput Generated?

* The activation function combined with the number of neurons in output layer determine the output

!SLIDE

# Simple Network Output Layer

```
.layer(1, new OutputLayer.Builder(LossFunctions.LossFunction.MSE)
.activation(Activation.IDENTITY)
.nIn(nHidden).nOut(1).build())
```				
!SLIDE

# Output Layer Explained

* Activation Function Identity
  * Emits what it recieves
* LossFunction
  * How error is calculated

!SLIDE


#Output Layer of a Neural Network Can be Configured for Different Purposes: 

* One of x possible classes
* True/False 
* Range of values
* More...

!SLIDE

# Settings important to all Neural Networks

* Learning Rate
  * Applies to whole Network
  * If output is 10 and expected output is 1 how big of a step to take to correct error
* Activation Function
  * Set per layer
  * Sets the "trigger" on what output to emit
  * examples, sigmoid, ReLU, tanh
  * More on these later
  
!SLIDE

# Settings important to all Neural Networks...

* Loss Function
  * Set on Output Layer
  * How error is calculated
  * Example Mean Squared Error
  * More on this later
* Updater
  * Applies to whole Network
  * How weights are updated
  * Example Stochastic Gradient Descent
  
!SLIDE

# Simple Network Setting

* LearningRate 0.005
* Updater Nesterovs variant of Stochastic Gradient Descent with Momentum
* Output Activation Identity
* Hidden Layer Activation TANH
* Number of Epochs 500

!SLIDE

# Extrapolate from Simple Network

* Simple Network took one value in and one value out and trained the network to learn the correct value 
* More complex data same process
* Input can be images, row data, documents
* Output can be T/F, range of values, labels of a class



!SLIDE

!SLIDE

* Simple Network Demo
* Simple Network Details
* Simple Network Lab
* Important Network Settings
* **&rArr;**VGG-16 Demo

!SLIDE



# VGG-16 Demo

*  Instructor demonstration of a more complex Neural Network



!SLIDE

# Questions

* What is the Learning Rate and what effect does it have on the Neural Network?
* Activation Function is set per Layer or for the whole Network?
* The error of the output compared to the expected output is? 
  A. Loss Function
  B. Sigmoid Function
  C. Learning Rate
* Stochastic Gradient Descent is an example of
  A. Updater
  B. Activation Function
  C. Loss Function


!SLIDE

